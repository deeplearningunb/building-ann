{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDES NEURAIS ARTIFICIAIS\n",
    "## Evaluate Improve e Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 - Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar as libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZaTwK7ojXr2F",
    "outputId": "0b27a96d-d11a-43e8-ab4b-87c1f01896fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X >>\n",
      " [[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n",
      "y >>\n",
      " [1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "print(\"X >>\\n\",X)\n",
    "print(\"y >>\\n\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando os dados categóricos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X>>\n",
      " [[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding the \"Gender\" column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "print('X>>\\n', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X>>\n",
      " [[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding the \"Geography\" column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print('X>>\\n', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividindo o dataset em conjunto de treinamento e conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parte 2 -Vamos construir uma ANN!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 797us/step - loss: 0.6633 - accuracy: 0.6864\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 734us/step - loss: 0.5004 - accuracy: 0.7966\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 616us/step - loss: 0.4426 - accuracy: 0.8094\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.4256 - accuracy: 0.8150\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 767us/step - loss: 0.4155 - accuracy: 0.8216\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 744us/step - loss: 0.4034 - accuracy: 0.8286\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.3899 - accuracy: 0.8378\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 595us/step - loss: 0.3771 - accuracy: 0.8431\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 543us/step - loss: 0.3667 - accuracy: 0.8481\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 545us/step - loss: 0.3593 - accuracy: 0.8521\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 664us/step - loss: 0.3546 - accuracy: 0.8534\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.3514 - accuracy: 0.8541\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 592us/step - loss: 0.3492 - accuracy: 0.8569\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 584us/step - loss: 0.3470 - accuracy: 0.8579\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 529us/step - loss: 0.3462 - accuracy: 0.8584\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 585us/step - loss: 0.3450 - accuracy: 0.8587\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 569us/step - loss: 0.3440 - accuracy: 0.8599\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 545us/step - loss: 0.3435 - accuracy: 0.8605\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.3427 - accuracy: 0.8606\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.3423 - accuracy: 0.8595\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.3417 - accuracy: 0.8604\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 573us/step - loss: 0.3416 - accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 566us/step - loss: 0.3409 - accuracy: 0.8596\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 531us/step - loss: 0.3404 - accuracy: 0.8599\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 559us/step - loss: 0.3400 - accuracy: 0.8601\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 538us/step - loss: 0.3397 - accuracy: 0.8611\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 534us/step - loss: 0.3396 - accuracy: 0.8608\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 605us/step - loss: 0.3388 - accuracy: 0.8605\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 635us/step - loss: 0.3385 - accuracy: 0.8620\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 565us/step - loss: 0.3380 - accuracy: 0.8611\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 570us/step - loss: 0.3378 - accuracy: 0.8605\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.3375 - accuracy: 0.8606\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 777us/step - loss: 0.3370 - accuracy: 0.8625\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.3371 - accuracy: 0.8629\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 590us/step - loss: 0.3367 - accuracy: 0.8616\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.3363 - accuracy: 0.8621\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 652us/step - loss: 0.3361 - accuracy: 0.8633\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.3355 - accuracy: 0.8627\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 569us/step - loss: 0.3355 - accuracy: 0.8611\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3352 - accuracy: 0.8622\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 553us/step - loss: 0.3350 - accuracy: 0.8614\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 660us/step - loss: 0.3349 - accuracy: 0.8622\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 583us/step - loss: 0.3350 - accuracy: 0.8609\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3350 - accuracy: 0.8627\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 581us/step - loss: 0.3342 - accuracy: 0.8620\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 527us/step - loss: 0.3347 - accuracy: 0.8639\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 667us/step - loss: 0.3340 - accuracy: 0.8641\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.3342 - accuracy: 0.8641\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 768us/step - loss: 0.3339 - accuracy: 0.8629\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 547us/step - loss: 0.3341 - accuracy: 0.8639\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 525us/step - loss: 0.3337 - accuracy: 0.8648\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 617us/step - loss: 0.3336 - accuracy: 0.8637\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 764us/step - loss: 0.3335 - accuracy: 0.8626\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 598us/step - loss: 0.3330 - accuracy: 0.8634\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 744us/step - loss: 0.3330 - accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 737us/step - loss: 0.3334 - accuracy: 0.8629\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 605us/step - loss: 0.3326 - accuracy: 0.8618\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 567us/step - loss: 0.3330 - accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 784us/step - loss: 0.3332 - accuracy: 0.8635\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.3331 - accuracy: 0.8629\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 592us/step - loss: 0.3329 - accuracy: 0.8625\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.3323 - accuracy: 0.8635\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 612us/step - loss: 0.3328 - accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 746us/step - loss: 0.3325 - accuracy: 0.8640\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.3320 - accuracy: 0.8639\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.3327 - accuracy: 0.8622\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.3324 - accuracy: 0.8634\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.3322 - accuracy: 0.8650\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 742us/step - loss: 0.3324 - accuracy: 0.8624\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.3322 - accuracy: 0.8624\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 608us/step - loss: 0.3324 - accuracy: 0.8626\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 576us/step - loss: 0.3323 - accuracy: 0.8627\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3321 - accuracy: 0.8621\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 571us/step - loss: 0.3323 - accuracy: 0.8625\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 560us/step - loss: 0.3317 - accuracy: 0.8643\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 537us/step - loss: 0.3321 - accuracy: 0.8622\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 538us/step - loss: 0.3318 - accuracy: 0.8636\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 616us/step - loss: 0.3317 - accuracy: 0.8637\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 605us/step - loss: 0.3319 - accuracy: 0.8645\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 584us/step - loss: 0.3312 - accuracy: 0.8635\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 545us/step - loss: 0.3318 - accuracy: 0.8624\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 545us/step - loss: 0.3315 - accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3315 - accuracy: 0.8624\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 568us/step - loss: 0.3318 - accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 632us/step - loss: 0.3313 - accuracy: 0.8615\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 616us/step - loss: 0.3318 - accuracy: 0.8644\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.3314 - accuracy: 0.8627\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.3315 - accuracy: 0.8629\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3314 - accuracy: 0.8629\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 569us/step - loss: 0.3314 - accuracy: 0.8620\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 579us/step - loss: 0.3314 - accuracy: 0.8624\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 613us/step - loss: 0.3312 - accuracy: 0.8626\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 653us/step - loss: 0.3310 - accuracy: 0.8627\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.3313 - accuracy: 0.8624\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 746us/step - loss: 0.3313 - accuracy: 0.8621\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 612us/step - loss: 0.3313 - accuracy: 0.8636\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 586us/step - loss: 0.3311 - accuracy: 0.8639\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 528us/step - loss: 0.3311 - accuracy: 0.8639\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 747us/step - loss: 0.3309 - accuracy: 0.8636\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.3313 - accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feac004cfd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 - Fazendo predições e avaliando o modelo\n",
    "\n",
    "## Prevendo os resultados com o conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21772182],\n",
       "       [0.27619475],\n",
       "       [0.13028958],\n",
       "       ...,\n",
       "       [0.09519646],\n",
       "       [0.14674127],\n",
       "       [0.20815203]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando uma Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1528   67]\n",
      " [ 206  199]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Avaliando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the ANN\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-b2917738c23b>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8403750061988831 0.013829881795730697\n"
     ]
    }
   ],
   "source": [
    "print(mean,variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melhorando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving the ANN\n",
    "# Dropout Regularization to reduce overfitting if needed\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-b2917738c23b>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8211250007152557 0.015180681964707187\n"
     ]
    }
   ],
   "source": [
    "print(mean,variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-564c6c36d575>:16: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "\n",
    "parameters = {\n",
    "    'batch_size': [10, 25, 32],\n",
    "    'epochs': [50, 100],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           scoring = 'accuracy',\n",
    "                           param_grid = parameters,\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 753us/step - loss: 0.4947 - accuracy: 0.7971\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 567us/step - loss: 0.4362 - accuracy: 0.7971\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 602us/step - loss: 0.4316 - accuracy: 0.7971\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 1s 725us/step - loss: 0.4280 - accuracy: 0.7971\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 611us/step - loss: 0.4271 - accuracy: 0.7971\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 634us/step - loss: 0.4291 - accuracy: 0.8133\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 560us/step - loss: 0.4234 - accuracy: 0.8249\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 535us/step - loss: 0.4264 - accuracy: 0.8271\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 608us/step - loss: 0.4234 - accuracy: 0.8257\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 642us/step - loss: 0.4235 - accuracy: 0.8282\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 574us/step - loss: 0.4263 - accuracy: 0.8283\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 611us/step - loss: 0.4279 - accuracy: 0.8303\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 621us/step - loss: 0.4233 - accuracy: 0.8281\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 579us/step - loss: 0.4250 - accuracy: 0.8293\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 553us/step - loss: 0.4246 - accuracy: 0.8304\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 625us/step - loss: 0.4240 - accuracy: 0.8313\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4222 - accuracy: 0.8299\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 1s 733us/step - loss: 0.4265 - accuracy: 0.8296\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 1s 730us/step - loss: 0.4256 - accuracy: 0.8326\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 0s 648us/step - loss: 0.4240 - accuracy: 0.8314\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 675us/step - loss: 0.4227 - accuracy: 0.8342\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 582us/step - loss: 0.4197 - accuracy: 0.8310\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 609us/step - loss: 0.4235 - accuracy: 0.8315\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 1s 739us/step - loss: 0.4241 - accuracy: 0.8325\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 625us/step - loss: 0.4220 - accuracy: 0.8347\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 570us/step - loss: 0.4203 - accuracy: 0.8324\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 619us/step - loss: 0.4249 - accuracy: 0.8301\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 1s 708us/step - loss: 0.4246 - accuracy: 0.8308\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 658us/step - loss: 0.4244 - accuracy: 0.8314\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 0s 534us/step - loss: 0.4209 - accuracy: 0.8333\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 1s 725us/step - loss: 0.4227 - accuracy: 0.8321\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 673us/step - loss: 0.4210 - accuracy: 0.8328\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 590us/step - loss: 0.4258 - accuracy: 0.8304\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 547us/step - loss: 0.4221 - accuracy: 0.8331\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 650us/step - loss: 0.4218 - accuracy: 0.8325\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 1s 703us/step - loss: 0.4219 - accuracy: 0.8313\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 594us/step - loss: 0.4215 - accuracy: 0.8301\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 629us/step - loss: 0.4217 - accuracy: 0.8335\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 619us/step - loss: 0.4218 - accuracy: 0.8317\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 652us/step - loss: 0.4216 - accuracy: 0.8308\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 560us/step - loss: 0.4192 - accuracy: 0.8299\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 578us/step - loss: 0.4233 - accuracy: 0.8310\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.4255 - accuracy: 0.8303\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 1s 719us/step - loss: 0.4223 - accuracy: 0.8303\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 579us/step - loss: 0.4240 - accuracy: 0.8314\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 566us/step - loss: 0.4196 - accuracy: 0.8311\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4250 - accuracy: 0.8310\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 639us/step - loss: 0.4208 - accuracy: 0.8321\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 1s 739us/step - loss: 0.4235 - accuracy: 0.8293\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 1s 713us/step - loss: 0.4214 - accuracy: 0.8321\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 630us/step - loss: 0.5094 - accuracy: 0.7961\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 644us/step - loss: 0.4426 - accuracy: 0.7967\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 558us/step - loss: 0.4395 - accuracy: 0.7967\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 1s 716us/step - loss: 0.4381 - accuracy: 0.7967\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 576us/step - loss: 0.4348 - accuracy: 0.7967\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 568us/step - loss: 0.4340 - accuracy: 0.7967\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4299 - accuracy: 0.7967\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 648us/step - loss: 0.4295 - accuracy: 0.7967\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 552us/step - loss: 0.4288 - accuracy: 0.7967\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 675us/step - loss: 0.4304 - accuracy: 0.7967\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 588us/step - loss: 0.4285 - accuracy: 0.7967\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 527us/step - loss: 0.4277 - accuracy: 0.7967\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 519us/step - loss: 0.4292 - accuracy: 0.7967\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 530us/step - loss: 0.4261 - accuracy: 0.8089\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 536us/step - loss: 0.4257 - accuracy: 0.8190\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 578us/step - loss: 0.4254 - accuracy: 0.8246\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 623us/step - loss: 0.4284 - accuracy: 0.8229\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 621us/step - loss: 0.4294 - accuracy: 0.8242\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 682us/step - loss: 0.4283 - accuracy: 0.8256\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 0s 558us/step - loss: 0.4270 - accuracy: 0.8228\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 1s 722us/step - loss: 0.4259 - accuracy: 0.8272\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 578us/step - loss: 0.4283 - accuracy: 0.8244\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 641us/step - loss: 0.4275 - accuracy: 0.8229\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 1s 716us/step - loss: 0.4220 - accuracy: 0.8244\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 1s 721us/step - loss: 0.4287 - accuracy: 0.8224\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 668us/step - loss: 0.4212 - accuracy: 0.8263\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 644us/step - loss: 0.4272 - accuracy: 0.8258\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 599us/step - loss: 0.4275 - accuracy: 0.8278\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 651us/step - loss: 0.4268 - accuracy: 0.8265\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 1s 734us/step - loss: 0.4255 - accuracy: 0.8269\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 654us/step - loss: 0.4271 - accuracy: 0.8249\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 632us/step - loss: 0.4226 - accuracy: 0.8272\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 692us/step - loss: 0.4239 - accuracy: 0.8274\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 667us/step - loss: 0.4241 - accuracy: 0.8274\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 622us/step - loss: 0.4211 - accuracy: 0.8308\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 1s 709us/step - loss: 0.4243 - accuracy: 0.8278\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 689us/step - loss: 0.4278 - accuracy: 0.8301\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 1s 748us/step - loss: 0.4203 - accuracy: 0.8285\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 617us/step - loss: 0.4238 - accuracy: 0.8283\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 607us/step - loss: 0.4245 - accuracy: 0.8303\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 675us/step - loss: 0.4233 - accuracy: 0.8310\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 1s 755us/step - loss: 0.4254 - accuracy: 0.8274\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 608us/step - loss: 0.4280 - accuracy: 0.8285\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 673us/step - loss: 0.4240 - accuracy: 0.8288\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 1s 754us/step - loss: 0.4234 - accuracy: 0.8310\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 1s 758us/step - loss: 0.4253 - accuracy: 0.8303\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 1s 740us/step - loss: 0.4238 - accuracy: 0.8268\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 1s 726us/step - loss: 0.4284 - accuracy: 0.8296\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 582us/step - loss: 0.4227 - accuracy: 0.8278\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 1s 736us/step - loss: 0.4233 - accuracy: 0.8289\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 607us/step - loss: 0.4947 - accuracy: 0.7956\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 645us/step - loss: 0.4301 - accuracy: 0.7956\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 1s 698us/step - loss: 0.4275 - accuracy: 0.7956\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 614us/step - loss: 0.4196 - accuracy: 0.7956\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 645us/step - loss: 0.4177 - accuracy: 0.8044\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 582us/step - loss: 0.4152 - accuracy: 0.8240\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 589us/step - loss: 0.4104 - accuracy: 0.8235\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 1s 753us/step - loss: 0.4126 - accuracy: 0.8214\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 1s 734us/step - loss: 0.4100 - accuracy: 0.8221\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 1s 705us/step - loss: 0.4107 - accuracy: 0.8215\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 1s 736us/step - loss: 0.4068 - accuracy: 0.8224\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 689us/step - loss: 0.4082 - accuracy: 0.8217\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 620us/step - loss: 0.4082 - accuracy: 0.8213\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 1s 708us/step - loss: 0.4096 - accuracy: 0.8239\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 615us/step - loss: 0.4114 - accuracy: 0.8240\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 1s 723us/step - loss: 0.4070 - accuracy: 0.8221\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 1s 705us/step - loss: 0.4081 - accuracy: 0.8243\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 579us/step - loss: 0.4073 - accuracy: 0.8257\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 605us/step - loss: 0.4024 - accuracy: 0.8300\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 1s 704us/step - loss: 0.4002 - accuracy: 0.8265\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 585us/step - loss: 0.4031 - accuracy: 0.8304\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 598us/step - loss: 0.4052 - accuracy: 0.8272\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 573us/step - loss: 0.4064 - accuracy: 0.8293\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 661us/step - loss: 0.4095 - accuracy: 0.8288\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 662us/step - loss: 0.4068 - accuracy: 0.8268\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 682us/step - loss: 0.4082 - accuracy: 0.8278\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 666us/step - loss: 0.4020 - accuracy: 0.8342\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 604us/step - loss: 0.4069 - accuracy: 0.8289\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 679us/step - loss: 0.4055 - accuracy: 0.8303\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 0s 575us/step - loss: 0.4043 - accuracy: 0.8324\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 683us/step - loss: 0.4082 - accuracy: 0.8335\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 1s 741us/step - loss: 0.4020 - accuracy: 0.8307\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 582us/step - loss: 0.3973 - accuracy: 0.8332\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 693us/step - loss: 0.4097 - accuracy: 0.8282\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 1s 746us/step - loss: 0.4036 - accuracy: 0.8396\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 662us/step - loss: 0.4029 - accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 1s 739us/step - loss: 0.4042 - accuracy: 0.8313\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 673us/step - loss: 0.4029 - accuracy: 0.8335\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 1s 696us/step - loss: 0.4072 - accuracy: 0.8319\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 566us/step - loss: 0.4028 - accuracy: 0.8343\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 664us/step - loss: 0.4023 - accuracy: 0.8338\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 1s 704us/step - loss: 0.4030 - accuracy: 0.8367\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 641us/step - loss: 0.3990 - accuracy: 0.8390\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 623us/step - loss: 0.4037 - accuracy: 0.8314\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 656us/step - loss: 0.4054 - accuracy: 0.8318\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 1s 744us/step - loss: 0.4022 - accuracy: 0.8346\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 656us/step - loss: 0.3996 - accuracy: 0.8365\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 609us/step - loss: 0.3970 - accuracy: 0.8342\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 692us/step - loss: 0.4042 - accuracy: 0.8324\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 1s 738us/step - loss: 0.4029 - accuracy: 0.8333\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 700us/step - loss: 0.4995 - accuracy: 0.7969\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 620us/step - loss: 0.4402 - accuracy: 0.7975\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 664us/step - loss: 0.4366 - accuracy: 0.7975\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 635us/step - loss: 0.4320 - accuracy: 0.7975\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 571us/step - loss: 0.4302 - accuracy: 0.7975\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 619us/step - loss: 0.4256 - accuracy: 0.7975\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 624us/step - loss: 0.4264 - accuracy: 0.7975\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 609us/step - loss: 0.4276 - accuracy: 0.7975\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 692us/step - loss: 0.4300 - accuracy: 0.7975\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 615us/step - loss: 0.4285 - accuracy: 0.7983\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 646us/step - loss: 0.4271 - accuracy: 0.8124\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 1s 730us/step - loss: 0.4292 - accuracy: 0.8238\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 676us/step - loss: 0.4275 - accuracy: 0.8222\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 660us/step - loss: 0.4251 - accuracy: 0.8232\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 675us/step - loss: 0.4250 - accuracy: 0.8232\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 1s 721us/step - loss: 0.4249 - accuracy: 0.8236\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 1s 713us/step - loss: 0.4259 - accuracy: 0.8250\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 1s 724us/step - loss: 0.4267 - accuracy: 0.8246\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 1s 735us/step - loss: 0.4232 - accuracy: 0.8261\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 1s 739us/step - loss: 0.4231 - accuracy: 0.8274\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 1s 738us/step - loss: 0.4221 - accuracy: 0.8263\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 1s 756us/step - loss: 0.4247 - accuracy: 0.8300\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 664us/step - loss: 0.4231 - accuracy: 0.8290\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 677us/step - loss: 0.4225 - accuracy: 0.8279\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 650us/step - loss: 0.4214 - accuracy: 0.8294\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 661us/step - loss: 0.4199 - accuracy: 0.8282\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 1s 737us/step - loss: 0.4235 - accuracy: 0.8286\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 1s 723us/step - loss: 0.4239 - accuracy: 0.8304\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 1s 694us/step - loss: 0.4226 - accuracy: 0.8290\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 1s 735us/step - loss: 0.4222 - accuracy: 0.8281\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 648us/step - loss: 0.4224 - accuracy: 0.8289\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 622us/step - loss: 0.4240 - accuracy: 0.8308\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 599us/step - loss: 0.4251 - accuracy: 0.8268\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 606us/step - loss: 0.4213 - accuracy: 0.8293\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 653us/step - loss: 0.4209 - accuracy: 0.8322\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 591us/step - loss: 0.4230 - accuracy: 0.8299\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 635us/step - loss: 0.4228 - accuracy: 0.8308\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 604us/step - loss: 0.4201 - accuracy: 0.8318\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 596us/step - loss: 0.4209 - accuracy: 0.8339\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 590us/step - loss: 0.4241 - accuracy: 0.8292\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4258 - accuracy: 0.8282\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 644us/step - loss: 0.4230 - accuracy: 0.8317\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 572us/step - loss: 0.4210 - accuracy: 0.8317\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 616us/step - loss: 0.4232 - accuracy: 0.8321\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 589us/step - loss: 0.4189 - accuracy: 0.8306\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 1s 746us/step - loss: 0.4239 - accuracy: 0.8289\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 1s 723us/step - loss: 0.4209 - accuracy: 0.8325\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 1s 739us/step - loss: 0.4203 - accuracy: 0.8301\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 1s 707us/step - loss: 0.4233 - accuracy: 0.8307\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 0s 585us/step - loss: 0.4216 - accuracy: 0.8317\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 744us/step - loss: 0.4971 - accuracy: 0.7936\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 609us/step - loss: 0.4413 - accuracy: 0.7937\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 658us/step - loss: 0.4392 - accuracy: 0.7937\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 595us/step - loss: 0.4331 - accuracy: 0.7937\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 568us/step - loss: 0.4324 - accuracy: 0.7937\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 1s 705us/step - loss: 0.4312 - accuracy: 0.7981\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 1s 698us/step - loss: 0.4291 - accuracy: 0.8199\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 1s 695us/step - loss: 0.4317 - accuracy: 0.8215\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 586us/step - loss: 0.4285 - accuracy: 0.8232\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 585us/step - loss: 0.4296 - accuracy: 0.8250\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 1s 697us/step - loss: 0.4289 - accuracy: 0.8240\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 564us/step - loss: 0.4279 - accuracy: 0.8256\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 599us/step - loss: 0.4281 - accuracy: 0.8264\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 553us/step - loss: 0.4284 - accuracy: 0.8250\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 575us/step - loss: 0.4275 - accuracy: 0.8275\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 588us/step - loss: 0.4264 - accuracy: 0.8288\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 590us/step - loss: 0.4268 - accuracy: 0.8265\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 577us/step - loss: 0.4295 - accuracy: 0.8253\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 584us/step - loss: 0.4218 - accuracy: 0.8301\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 0s 681us/step - loss: 0.4253 - accuracy: 0.8261\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 688us/step - loss: 0.4257 - accuracy: 0.8258\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 596us/step - loss: 0.4221 - accuracy: 0.8286\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 592us/step - loss: 0.4253 - accuracy: 0.8253\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 642us/step - loss: 0.4265 - accuracy: 0.8253\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 584us/step - loss: 0.4244 - accuracy: 0.8264\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 663us/step - loss: 0.4239 - accuracy: 0.8226\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 566us/step - loss: 0.4234 - accuracy: 0.8285\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 641us/step - loss: 0.4267 - accuracy: 0.8268\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 1s 731us/step - loss: 0.4267 - accuracy: 0.8264\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 0s 660us/step - loss: 0.4248 - accuracy: 0.8283\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 674us/step - loss: 0.4270 - accuracy: 0.8296\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 1s 787us/step - loss: 0.4206 - accuracy: 0.8276\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 590us/step - loss: 0.4261 - accuracy: 0.8314\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 559us/step - loss: 0.4204 - accuracy: 0.8292\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 572us/step - loss: 0.4232 - accuracy: 0.8278\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 617us/step - loss: 0.4222 - accuracy: 0.8283\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 659us/step - loss: 0.4245 - accuracy: 0.8274\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 621us/step - loss: 0.4250 - accuracy: 0.8290\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 604us/step - loss: 0.4246 - accuracy: 0.8272\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 588us/step - loss: 0.4238 - accuracy: 0.8276\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 1s 722us/step - loss: 0.4228 - accuracy: 0.8272\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 661us/step - loss: 0.4219 - accuracy: 0.8306\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 657us/step - loss: 0.4238 - accuracy: 0.8306\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 580us/step - loss: 0.4246 - accuracy: 0.8289\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.4209 - accuracy: 0.8288\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 602us/step - loss: 0.4253 - accuracy: 0.8278\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 677us/step - loss: 0.4230 - accuracy: 0.8283\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 588us/step - loss: 0.4229 - accuracy: 0.8304\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 565us/step - loss: 0.4248 - accuracy: 0.8256\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 0s 669us/step - loss: 0.4228 - accuracy: 0.8274\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 622us/step - loss: 0.5040 - accuracy: 0.7936\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 579us/step - loss: 0.4408 - accuracy: 0.7944\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 631us/step - loss: 0.4372 - accuracy: 0.7944\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 596us/step - loss: 0.4371 - accuracy: 0.7944\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 626us/step - loss: 0.4334 - accuracy: 0.7944\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 1s 762us/step - loss: 0.4332 - accuracy: 0.7944\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 650us/step - loss: 0.4331 - accuracy: 0.7944\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 667us/step - loss: 0.4263 - accuracy: 0.7944\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 561us/step - loss: 0.4303 - accuracy: 0.7964\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 1s 715us/step - loss: 0.4326 - accuracy: 0.8056\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 662us/step - loss: 0.4295 - accuracy: 0.8179\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 670us/step - loss: 0.4292 - accuracy: 0.8175\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 1s 734us/step - loss: 0.4270 - accuracy: 0.8249\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 1s 701us/step - loss: 0.4280 - accuracy: 0.8243\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 621us/step - loss: 0.4299 - accuracy: 0.8224\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4252 - accuracy: 0.8247\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 688us/step - loss: 0.4245 - accuracy: 0.8261\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 656us/step - loss: 0.4254 - accuracy: 0.8246\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 1s 748us/step - loss: 0.4260 - accuracy: 0.8268\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 1s 722us/step - loss: 0.4269 - accuracy: 0.8243\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 1s 710us/step - loss: 0.4255 - accuracy: 0.8272\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 1s 747us/step - loss: 0.4256 - accuracy: 0.8283\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 1s 694us/step - loss: 0.4266 - accuracy: 0.8251\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 1s 716us/step - loss: 0.4284 - accuracy: 0.8267\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 687us/step - loss: 0.4259 - accuracy: 0.8294\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 1s 732us/step - loss: 0.4272 - accuracy: 0.8274\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 624us/step - loss: 0.4265 - accuracy: 0.8268\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 620us/step - loss: 0.4250 - accuracy: 0.8265\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 1s 713us/step - loss: 0.4268 - accuracy: 0.8283\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 1s 731us/step - loss: 0.4252 - accuracy: 0.8285\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 689us/step - loss: 0.4255 - accuracy: 0.8274\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 627us/step - loss: 0.4240 - accuracy: 0.8283\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 587us/step - loss: 0.4270 - accuracy: 0.8281\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 1s 720us/step - loss: 0.4242 - accuracy: 0.8282\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 582us/step - loss: 0.4242 - accuracy: 0.8282\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 600us/step - loss: 0.4271 - accuracy: 0.8263\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 619us/step - loss: 0.4240 - accuracy: 0.8301\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 604us/step - loss: 0.4253 - accuracy: 0.8317\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 577us/step - loss: 0.4254 - accuracy: 0.8278\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 603us/step - loss: 0.4236 - accuracy: 0.8293\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 1s 709us/step - loss: 0.4247 - accuracy: 0.8311\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 1s 748us/step - loss: 0.4264 - accuracy: 0.8288\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 663us/step - loss: 0.4252 - accuracy: 0.8275\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 1s 739us/step - loss: 0.4249 - accuracy: 0.8278\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 556us/step - loss: 0.4251 - accuracy: 0.8289\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 642us/step - loss: 0.4244 - accuracy: 0.8310\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 668us/step - loss: 0.4192 - accuracy: 0.8321\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 613us/step - loss: 0.4259 - accuracy: 0.8268\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 1s 726us/step - loss: 0.4263 - accuracy: 0.8301\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 1s 742us/step - loss: 0.4275 - accuracy: 0.8297\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 736us/step - loss: 0.4995 - accuracy: 0.7968\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 616us/step - loss: 0.4367 - accuracy: 0.7969\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 619us/step - loss: 0.4379 - accuracy: 0.7969\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 571us/step - loss: 0.4355 - accuracy: 0.7969\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 550us/step - loss: 0.4344 - accuracy: 0.7969\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 665us/step - loss: 0.4341 - accuracy: 0.7969\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 1s 767us/step - loss: 0.4306 - accuracy: 0.7969\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 612us/step - loss: 0.4283 - accuracy: 0.7969\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 1s 726us/step - loss: 0.4271 - accuracy: 0.7969\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 645us/step - loss: 0.4275 - accuracy: 0.8049\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 620us/step - loss: 0.4264 - accuracy: 0.8194\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 1s 760us/step - loss: 0.4277 - accuracy: 0.8206\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 668us/step - loss: 0.4290 - accuracy: 0.8210\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 665us/step - loss: 0.4265 - accuracy: 0.8236\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 1s 760us/step - loss: 0.4259 - accuracy: 0.8211\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 1s 745us/step - loss: 0.4254 - accuracy: 0.8249\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 678us/step - loss: 0.4241 - accuracy: 0.8267\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 1s 751us/step - loss: 0.4238 - accuracy: 0.8251\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 1s 772us/step - loss: 0.4247 - accuracy: 0.8261\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 1s 726us/step - loss: 0.4248 - accuracy: 0.8274\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 655us/step - loss: 0.4242 - accuracy: 0.8276\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 1s 700us/step - loss: 0.4263 - accuracy: 0.8257\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 619us/step - loss: 0.4244 - accuracy: 0.8275\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 574us/step - loss: 0.4212 - accuracy: 0.8282\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 582us/step - loss: 0.4237 - accuracy: 0.8276\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 604us/step - loss: 0.4236 - accuracy: 0.8267\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 602us/step - loss: 0.4263 - accuracy: 0.8290\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 623us/step - loss: 0.4217 - accuracy: 0.8282\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 683us/step - loss: 0.4229 - accuracy: 0.8272\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 1s 744us/step - loss: 0.4216 - accuracy: 0.8261\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 603us/step - loss: 0.4237 - accuracy: 0.8286\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 608us/step - loss: 0.4179 - accuracy: 0.8303\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 625us/step - loss: 0.4223 - accuracy: 0.8264\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 572us/step - loss: 0.4190 - accuracy: 0.8275\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 575us/step - loss: 0.4231 - accuracy: 0.8254\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 550us/step - loss: 0.4225 - accuracy: 0.8282\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 595us/step - loss: 0.4214 - accuracy: 0.8272\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 548us/step - loss: 0.4252 - accuracy: 0.8276\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 1s 708us/step - loss: 0.4230 - accuracy: 0.8283\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 591us/step - loss: 0.4248 - accuracy: 0.8257\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 641us/step - loss: 0.4169 - accuracy: 0.8296\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 689us/step - loss: 0.4223 - accuracy: 0.8263\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 672us/step - loss: 0.4211 - accuracy: 0.8292\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 589us/step - loss: 0.4211 - accuracy: 0.8283\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 598us/step - loss: 0.4204 - accuracy: 0.8311\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 589us/step - loss: 0.4212 - accuracy: 0.8293\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 545us/step - loss: 0.4216 - accuracy: 0.8290\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 624us/step - loss: 0.4224 - accuracy: 0.8297\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4225 - accuracy: 0.8294\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 0s 657us/step - loss: 0.4181 - accuracy: 0.8296\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 744us/step - loss: 0.4920 - accuracy: 0.7949\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 1s 717us/step - loss: 0.4348 - accuracy: 0.7962\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 660us/step - loss: 0.4296 - accuracy: 0.7962\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 1s 709us/step - loss: 0.4266 - accuracy: 0.7962\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 1s 712us/step - loss: 0.4256 - accuracy: 0.7962\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 1s 717us/step - loss: 0.4267 - accuracy: 0.8085\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 561us/step - loss: 0.4229 - accuracy: 0.8181\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 639us/step - loss: 0.4256 - accuracy: 0.8256\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 1s 705us/step - loss: 0.4220 - accuracy: 0.8247\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 599us/step - loss: 0.4234 - accuracy: 0.8265\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 618us/step - loss: 0.4250 - accuracy: 0.8233\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 546us/step - loss: 0.4210 - accuracy: 0.8272\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 1s 702us/step - loss: 0.4210 - accuracy: 0.8267\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 662us/step - loss: 0.4209 - accuracy: 0.8276\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 648us/step - loss: 0.4209 - accuracy: 0.8289\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 1s 726us/step - loss: 0.4222 - accuracy: 0.8264\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 630us/step - loss: 0.4215 - accuracy: 0.8263\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 662us/step - loss: 0.4222 - accuracy: 0.8294\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 635us/step - loss: 0.4208 - accuracy: 0.8275\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 1s 732us/step - loss: 0.4232 - accuracy: 0.8296\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 1s 696us/step - loss: 0.4193 - accuracy: 0.8286\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 1s 749us/step - loss: 0.4225 - accuracy: 0.8292\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 629us/step - loss: 0.4231 - accuracy: 0.8282\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 641us/step - loss: 0.4173 - accuracy: 0.8318\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 1s 728us/step - loss: 0.4224 - accuracy: 0.8300\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 1s 753us/step - loss: 0.4201 - accuracy: 0.8281\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 1s 713us/step - loss: 0.4211 - accuracy: 0.8306\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 681us/step - loss: 0.4199 - accuracy: 0.8286\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 1s 694us/step - loss: 0.4250 - accuracy: 0.8301\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 1s 747us/step - loss: 0.4208 - accuracy: 0.8279\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 1s 725us/step - loss: 0.4179 - accuracy: 0.8285\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 599us/step - loss: 0.4209 - accuracy: 0.8286\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 646us/step - loss: 0.4195 - accuracy: 0.8307\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 654us/step - loss: 0.4203 - accuracy: 0.8276\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 1s 721us/step - loss: 0.4240 - accuracy: 0.8283\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 662us/step - loss: 0.4226 - accuracy: 0.8294\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 1s 708us/step - loss: 0.4216 - accuracy: 0.8282\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 643us/step - loss: 0.4157 - accuracy: 0.8317\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 1s 738us/step - loss: 0.4216 - accuracy: 0.8288\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 643us/step - loss: 0.4207 - accuracy: 0.8303\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 1s 703us/step - loss: 0.4231 - accuracy: 0.8294\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 1s 696us/step - loss: 0.4212 - accuracy: 0.8304\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 621us/step - loss: 0.4182 - accuracy: 0.8288\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 1s 705us/step - loss: 0.4202 - accuracy: 0.8322\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 642us/step - loss: 0.4207 - accuracy: 0.8292\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 591us/step - loss: 0.4203 - accuracy: 0.8276\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 1s 738us/step - loss: 0.4225 - accuracy: 0.8299\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 1s 708us/step - loss: 0.4191 - accuracy: 0.8286\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4237 - accuracy: 0.8290\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 0s 676us/step - loss: 0.4203 - accuracy: 0.8324\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 706us/step - loss: 0.4919 - accuracy: 0.7957\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 593us/step - loss: 0.4351 - accuracy: 0.7957\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 652us/step - loss: 0.4313 - accuracy: 0.7957\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 673us/step - loss: 0.4295 - accuracy: 0.7957\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 611us/step - loss: 0.4238 - accuracy: 0.7957\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 691us/step - loss: 0.4277 - accuracy: 0.7957\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 1s 710us/step - loss: 0.4265 - accuracy: 0.8068\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 659us/step - loss: 0.4223 - accuracy: 0.8249\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 625us/step - loss: 0.4230 - accuracy: 0.8275\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 550us/step - loss: 0.4230 - accuracy: 0.8308\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 598us/step - loss: 0.4230 - accuracy: 0.8300\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 668us/step - loss: 0.4216 - accuracy: 0.8296\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4206 - accuracy: 0.8311\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 558us/step - loss: 0.4200 - accuracy: 0.8317\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 653us/step - loss: 0.4178 - accuracy: 0.8310\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 599us/step - loss: 0.4211 - accuracy: 0.8332\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 650us/step - loss: 0.4190 - accuracy: 0.8343\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 674us/step - loss: 0.4212 - accuracy: 0.8329\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 1s 743us/step - loss: 0.4179 - accuracy: 0.8335\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 1s 712us/step - loss: 0.4202 - accuracy: 0.8340\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 1s 705us/step - loss: 0.4194 - accuracy: 0.8332\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 658us/step - loss: 0.4201 - accuracy: 0.8338\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 623us/step - loss: 0.4198 - accuracy: 0.8333\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 1s 696us/step - loss: 0.4188 - accuracy: 0.8325\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 613us/step - loss: 0.4183 - accuracy: 0.8338\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 1s 729us/step - loss: 0.4196 - accuracy: 0.8336\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 1s 699us/step - loss: 0.4154 - accuracy: 0.8339\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 672us/step - loss: 0.4234 - accuracy: 0.8338\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 621us/step - loss: 0.4183 - accuracy: 0.8331\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 0s 626us/step - loss: 0.4247 - accuracy: 0.8313\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 579us/step - loss: 0.4137 - accuracy: 0.8307\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 628us/step - loss: 0.4154 - accuracy: 0.8347\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 1s 727us/step - loss: 0.4178 - accuracy: 0.8339\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 586us/step - loss: 0.4168 - accuracy: 0.8329\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 669us/step - loss: 0.4173 - accuracy: 0.8339\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 685us/step - loss: 0.4160 - accuracy: 0.8324\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 643us/step - loss: 0.4186 - accuracy: 0.8351\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 1s 724us/step - loss: 0.4204 - accuracy: 0.8339\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 615us/step - loss: 0.4194 - accuracy: 0.8347\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 1s 718us/step - loss: 0.4174 - accuracy: 0.8321\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 667us/step - loss: 0.4190 - accuracy: 0.8332\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 672us/step - loss: 0.4175 - accuracy: 0.8343\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 657us/step - loss: 0.4175 - accuracy: 0.8325\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 554us/step - loss: 0.4193 - accuracy: 0.8325\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 644us/step - loss: 0.4185 - accuracy: 0.8322\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 1s 744us/step - loss: 0.4178 - accuracy: 0.8354\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 626us/step - loss: 0.4201 - accuracy: 0.8322\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 654us/step - loss: 0.4192 - accuracy: 0.8329\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 670us/step - loss: 0.4161 - accuracy: 0.8339\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 0s 586us/step - loss: 0.4175 - accuracy: 0.8315\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 695us/step - loss: 0.4853 - accuracy: 0.7958\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 621us/step - loss: 0.4385 - accuracy: 0.7961\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 604us/step - loss: 0.4341 - accuracy: 0.7961\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 594us/step - loss: 0.4316 - accuracy: 0.7961\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 644us/step - loss: 0.4257 - accuracy: 0.7961\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 595us/step - loss: 0.4285 - accuracy: 0.8075\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 659us/step - loss: 0.4283 - accuracy: 0.8206\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 1s 746us/step - loss: 0.4291 - accuracy: 0.8214\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 1s 740us/step - loss: 0.4266 - accuracy: 0.8208\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 656us/step - loss: 0.4255 - accuracy: 0.8265\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 681us/step - loss: 0.4285 - accuracy: 0.8238\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 578us/step - loss: 0.4271 - accuracy: 0.8261\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 593us/step - loss: 0.4254 - accuracy: 0.8265\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 558us/step - loss: 0.4241 - accuracy: 0.8251\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 564us/step - loss: 0.4273 - accuracy: 0.8265\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 594us/step - loss: 0.4266 - accuracy: 0.8265\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 568us/step - loss: 0.4261 - accuracy: 0.8257\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 567us/step - loss: 0.4250 - accuracy: 0.8293\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 552us/step - loss: 0.4254 - accuracy: 0.8263\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 0s 555us/step - loss: 0.4271 - accuracy: 0.8264\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 653us/step - loss: 0.4237 - accuracy: 0.8274\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 604us/step - loss: 0.4266 - accuracy: 0.8271\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 577us/step - loss: 0.4256 - accuracy: 0.8251\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 533us/step - loss: 0.4258 - accuracy: 0.8258\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.4280 - accuracy: 0.8265\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 674us/step - loss: 0.4211 - accuracy: 0.8279\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 678us/step - loss: 0.4267 - accuracy: 0.8271\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 583us/step - loss: 0.4233 - accuracy: 0.8293\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 590us/step - loss: 0.4225 - accuracy: 0.8276\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 0s 694us/step - loss: 0.4229 - accuracy: 0.8299\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 689us/step - loss: 0.4239 - accuracy: 0.8300\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 1s 721us/step - loss: 0.4236 - accuracy: 0.8275\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 1s 696us/step - loss: 0.4242 - accuracy: 0.8253\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 669us/step - loss: 0.4218 - accuracy: 0.8288\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 566us/step - loss: 0.4240 - accuracy: 0.8269\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 587us/step - loss: 0.4243 - accuracy: 0.8293\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 1s 729us/step - loss: 0.4238 - accuracy: 0.8272\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 1s 755us/step - loss: 0.4253 - accuracy: 0.8296\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 688us/step - loss: 0.4228 - accuracy: 0.8257\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 1s 751us/step - loss: 0.4234 - accuracy: 0.8271\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 583us/step - loss: 0.4256 - accuracy: 0.8297\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 566us/step - loss: 0.4257 - accuracy: 0.8285\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 613us/step - loss: 0.4255 - accuracy: 0.8275\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 546us/step - loss: 0.4245 - accuracy: 0.8279\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 578us/step - loss: 0.4237 - accuracy: 0.8271\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 607us/step - loss: 0.4225 - accuracy: 0.8275\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 627us/step - loss: 0.4223 - accuracy: 0.8268\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 609us/step - loss: 0.4243 - accuracy: 0.8265\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 1s 716us/step - loss: 0.4233 - accuracy: 0.8244\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 1s 729us/step - loss: 0.4244 - accuracy: 0.8294\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 742us/step - loss: 0.5374 - accuracy: 0.7962\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 1s 718us/step - loss: 0.4337 - accuracy: 0.7978\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 1s 761us/step - loss: 0.4255 - accuracy: 0.8144\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 1s 728us/step - loss: 0.4168 - accuracy: 0.8228\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 1s 751us/step - loss: 0.4171 - accuracy: 0.8254\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 1s 764us/step - loss: 0.4070 - accuracy: 0.8283\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 1s 707us/step - loss: 0.4046 - accuracy: 0.8310\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 1s 701us/step - loss: 0.3979 - accuracy: 0.8335\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 612us/step - loss: 0.3951 - accuracy: 0.8329\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 627us/step - loss: 0.3921 - accuracy: 0.8386\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 1s 747us/step - loss: 0.3930 - accuracy: 0.8328\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 663us/step - loss: 0.3947 - accuracy: 0.8353\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 1s 695us/step - loss: 0.3885 - accuracy: 0.8375\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 1s 716us/step - loss: 0.3825 - accuracy: 0.8399\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 1s 748us/step - loss: 0.3807 - accuracy: 0.8429\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 689us/step - loss: 0.3798 - accuracy: 0.8440\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 614us/step - loss: 0.3774 - accuracy: 0.8421\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 660us/step - loss: 0.3759 - accuracy: 0.8433\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 620us/step - loss: 0.3766 - accuracy: 0.8446\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 0s 694us/step - loss: 0.3758 - accuracy: 0.8426\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 606us/step - loss: 0.3731 - accuracy: 0.8460\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 611us/step - loss: 0.3726 - accuracy: 0.8429\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 610us/step - loss: 0.3792 - accuracy: 0.8418\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 577us/step - loss: 0.3724 - accuracy: 0.8432\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 656us/step - loss: 0.3715 - accuracy: 0.8442\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 617us/step - loss: 0.3741 - accuracy: 0.8439\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 675us/step - loss: 0.3699 - accuracy: 0.8449\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 594us/step - loss: 0.3737 - accuracy: 0.8439\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 610us/step - loss: 0.3666 - accuracy: 0.8486\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 1s 723us/step - loss: 0.3748 - accuracy: 0.8426\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 658us/step - loss: 0.3713 - accuracy: 0.8474\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 659us/step - loss: 0.3702 - accuracy: 0.8464\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 599us/step - loss: 0.3700 - accuracy: 0.8443\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 1s 702us/step - loss: 0.3735 - accuracy: 0.8456\n",
      "Epoch 35/50\n",
      "449/720 [=================>............] - ETA: 0s - loss: 0.3695 - accuracy: 0.8465"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m   return pack_sequence_as(\n\u001b[0m\u001b[1;32m    914\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \"\"\"\n\u001b[0;32m--> 803\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     final_index, packed = _packed_nest_with_indices(structure, flat_sequence, 0,\n\u001b[0m\u001b[1;32m    676\u001b[0m                                                     is_nested_fn, sequence_fn)\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_nested_fn, sequence_fn)\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m   \u001b[0msequence_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sequence_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_nested_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       new_index, child = _packed_nest_with_indices(s, flat, index, is_nested_fn,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1700cf034d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best params:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\nBest accuracy:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "print('Best params:\\n',grid_search.best_params_,'\\nBest accuracy:\\n',grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halving Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-225b1b7f08e4>:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "def build_classifier(optimizer, activation, init):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = init, activation = activation, input_dim = 12))\n",
    "#     classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = init, activation = activation))\n",
    "#     classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "\n",
    "parameters = {\n",
    "    'batch_size': [10, 50],\n",
    "    'epochs': [50, 100],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'activation': ['softmax', 'relu', 'tanh'],\n",
    "    'init': ['uniform', 'normal', 'zero']\n",
    "}\n",
    "\n",
    "halving_cv = HalvingGridSearchCV(estimator = classifier,\n",
    "                                  param_grid = parameters,\n",
    "                                  scoring=\"accuracy\", \n",
    "                                  n_jobs=-1, \n",
    "                                  min_resources=\"exhaust\", \n",
    "                                  factor=3,\n",
    "                                  cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 648us/step - loss: 0.4848 - accuracy: 0.8079\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 660us/step - loss: 0.4355 - accuracy: 0.8138\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 700us/step - loss: 0.4332 - accuracy: 0.8117\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 640us/step - loss: 0.4263 - accuracy: 0.8144\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 694us/step - loss: 0.4180 - accuracy: 0.8181\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 625us/step - loss: 0.4048 - accuracy: 0.8275\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 560us/step - loss: 0.3980 - accuracy: 0.8322\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 587us/step - loss: 0.3950 - accuracy: 0.8321\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 710us/step - loss: 0.3968 - accuracy: 0.8314\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.3923 - accuracy: 0.8334\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 608us/step - loss: 0.3945 - accuracy: 0.8345\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 706us/step - loss: 0.3885 - accuracy: 0.8379\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 674us/step - loss: 0.3936 - accuracy: 0.8340\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 575us/step - loss: 0.3883 - accuracy: 0.8380\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 748us/step - loss: 0.3853 - accuracy: 0.8399\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 692us/step - loss: 0.3895 - accuracy: 0.8363\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 643us/step - loss: 0.3861 - accuracy: 0.8353\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 646us/step - loss: 0.3796 - accuracy: 0.8419\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 656us/step - loss: 0.3866 - accuracy: 0.8359\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 618us/step - loss: 0.3872 - accuracy: 0.8376\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.3869 - accuracy: 0.8366\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 724us/step - loss: 0.3831 - accuracy: 0.8405\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.3857 - accuracy: 0.8401\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 635us/step - loss: 0.3865 - accuracy: 0.8361\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 740us/step - loss: 0.3814 - accuracy: 0.8425\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 770us/step - loss: 0.3863 - accuracy: 0.8375\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 650us/step - loss: 0.3820 - accuracy: 0.8421\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 583us/step - loss: 0.3822 - accuracy: 0.8418\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 669us/step - loss: 0.3829 - accuracy: 0.8388\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 567us/step - loss: 0.3837 - accuracy: 0.8438\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 578us/step - loss: 0.3756 - accuracy: 0.8428\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 731us/step - loss: 0.3873 - accuracy: 0.8374\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 674us/step - loss: 0.3821 - accuracy: 0.8425\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 662us/step - loss: 0.3811 - accuracy: 0.8440\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 627us/step - loss: 0.3765 - accuracy: 0.8426\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 699us/step - loss: 0.3814 - accuracy: 0.8400\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.3844 - accuracy: 0.8406\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 690us/step - loss: 0.3791 - accuracy: 0.8413\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.3779 - accuracy: 0.8431\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 681us/step - loss: 0.3801 - accuracy: 0.8411\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 783us/step - loss: 0.3821 - accuracy: 0.8391\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 652us/step - loss: 0.3800 - accuracy: 0.8432\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 547us/step - loss: 0.3768 - accuracy: 0.8422\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 574us/step - loss: 0.3798 - accuracy: 0.8428\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 605us/step - loss: 0.3820 - accuracy: 0.8428\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 698us/step - loss: 0.3774 - accuracy: 0.8430\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 758us/step - loss: 0.3772 - accuracy: 0.8461\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 752us/step - loss: 0.3771 - accuracy: 0.8444\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 658us/step - loss: 0.3777 - accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 663us/step - loss: 0.3778 - accuracy: 0.8432\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 597us/step - loss: 0.3753 - accuracy: 0.8428\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 545us/step - loss: 0.3756 - accuracy: 0.8456\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 569us/step - loss: 0.3732 - accuracy: 0.8435\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 604us/step - loss: 0.3844 - accuracy: 0.8430\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 591us/step - loss: 0.3746 - accuracy: 0.8499\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 562us/step - loss: 0.3735 - accuracy: 0.8472\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 571us/step - loss: 0.3748 - accuracy: 0.8453\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 671us/step - loss: 0.3721 - accuracy: 0.8416\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 628us/step - loss: 0.3750 - accuracy: 0.8461\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 564us/step - loss: 0.3737 - accuracy: 0.8482\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 550us/step - loss: 0.3754 - accuracy: 0.8449\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 579us/step - loss: 0.3752 - accuracy: 0.8430\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 539us/step - loss: 0.3732 - accuracy: 0.8441\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 555us/step - loss: 0.3751 - accuracy: 0.8466\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 564us/step - loss: 0.3785 - accuracy: 0.8450\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 634us/step - loss: 0.3745 - accuracy: 0.8462\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 697us/step - loss: 0.3734 - accuracy: 0.8465\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 647us/step - loss: 0.3709 - accuracy: 0.8472\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 723us/step - loss: 0.3725 - accuracy: 0.8479\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 597us/step - loss: 0.3746 - accuracy: 0.8426\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 569us/step - loss: 0.3697 - accuracy: 0.8475\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 546us/step - loss: 0.3742 - accuracy: 0.8418\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 748us/step - loss: 0.3715 - accuracy: 0.8485\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.3703 - accuracy: 0.8479\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 560us/step - loss: 0.3642 - accuracy: 0.8486\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 645us/step - loss: 0.3743 - accuracy: 0.8453\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 584us/step - loss: 0.3737 - accuracy: 0.8499\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 597us/step - loss: 0.3718 - accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 688us/step - loss: 0.3706 - accuracy: 0.8476\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 761us/step - loss: 0.3703 - accuracy: 0.8484\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 756us/step - loss: 0.3733 - accuracy: 0.8447\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 758us/step - loss: 0.3745 - accuracy: 0.8454\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 681us/step - loss: 0.3727 - accuracy: 0.8490\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.3695 - accuracy: 0.8468\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.3686 - accuracy: 0.8482\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 764us/step - loss: 0.3687 - accuracy: 0.8465\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 764us/step - loss: 0.3685 - accuracy: 0.8490\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 732us/step - loss: 0.3717 - accuracy: 0.8474\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 608us/step - loss: 0.3739 - accuracy: 0.8460\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 556us/step - loss: 0.3680 - accuracy: 0.8490\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 551us/step - loss: 0.3719 - accuracy: 0.8465\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 631us/step - loss: 0.3693 - accuracy: 0.8445\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 607us/step - loss: 0.3734 - accuracy: 0.8479\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 589us/step - loss: 0.3736 - accuracy: 0.8450\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 634us/step - loss: 0.3675 - accuracy: 0.8524\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 614us/step - loss: 0.3706 - accuracy: 0.8508\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 719us/step - loss: 0.3673 - accuracy: 0.8472\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 695us/step - loss: 0.3724 - accuracy: 0.8485\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.3675 - accuracy: 0.8489\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 639us/step - loss: 0.3721 - accuracy: 0.8489\n",
      "CPU times: user 1min 21s, sys: 7.21 s, total: 1min 28s\n",
      "Wall time: 14min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_result = halving_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      " {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'} \n",
      "Best accuracy:\n",
      " 0.8546933667083856\n"
     ]
    }
   ],
   "source": [
    "print('Best params:\\n',grid_result.best_params_,'\\nBest accuracy:\\n',grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 50, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 50, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 100, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 10, 'epochs': 100, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 50, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 50, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 100, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'softmax', 'batch_size': 50, 'epochs': 100, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.05728706112357291 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.0586206896551724 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.04574654883248827 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06623921624930532 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.05386379086832176 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.05386379086832175 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06905167032586478 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06320794062008055 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 50, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 50, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.0689655172413793 {'activation': 'relu', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.061297892533210954 {'activation': 'relu', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 100, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'relu', 'batch_size': 50, 'epochs': 100, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.04677468953879495 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.04094600719668248 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.048887747857785595 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.048887747857785595 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.048887747857785595 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.037931034482758634 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.05441287530365345 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.048765984909417075 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.04677468953879496 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06801063077005524 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.045746548832488285 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06623921624930532 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.046391807058874864 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.04677468953879495 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.04677468953879495 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.04429390544367286 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'zero', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06254605912833466 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.045454545454545456 {'activation': 'softmax', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.045454545454545456 {'activation': 'softmax', 'batch_size': 50, 'epochs': 50, 'init': 'zero', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.05292332282815917 {'activation': 'softmax', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.06022727272727272 {'activation': 'relu', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.051875964593242396 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.05888293821832552 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.053590118738870894 {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.03851920740154159 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.05025760088067269 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.050832430105329646 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.039837609415813886 {'activation': 'tanh', 'batch_size': 50, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.04204545454545455 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.03784278592124254 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.0479566996500209 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.04196860298322589 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.0421528113431623 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.03918395374901516 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.0438495031399426 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.04090909090909091 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.0412861411922385 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.03715405164607232 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.03903537281208562 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.04235146625814596 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.05087052110363497 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.026807964640612112 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.02217726496804905 {'activation': 'tanh', 'batch_size': 50, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.02356456232212754 {'activation': 'relu', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.022228188720442812 {'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.017792721152179305 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.019421941884345092 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.019768145601706626 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.0239571337839922 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.01221734630156372 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "{},{} with: {} 0.8211250007152557 0.010236083469633206 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "{},{} with: {} 0.8211250007152557 0.008993864442163551 {'activation': 'tanh', 'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mena, std, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}', mean, std, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['iter', 'n_resources', 'mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_activation', 'param_batch_size', 'param_epochs', 'param_init', 'param_optimizer', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'split5_train_score', 'split6_train_score', 'split7_train_score', 'split8_train_score', 'split9_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_input_parameters',\n",
       " '_check_is_fitted',\n",
       " '_check_n_features',\n",
       " '_check_refit_for_multimetric',\n",
       " '_checked_cv_orig',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_generate_candidate_params',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_n_samples_orig',\n",
       " '_pairwise',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " '_validate_data',\n",
       " 'aggressive_elimination',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'factor',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'max_resources',\n",
       " 'max_resources_',\n",
       " 'min_resources',\n",
       " 'min_resources_',\n",
       " 'multimetric_',\n",
       " 'n_candidates_',\n",
       " 'n_features_in_',\n",
       " 'n_iterations_',\n",
       " 'n_jobs',\n",
       " 'n_possible_iterations_',\n",
       " 'n_remaining_candidates_',\n",
       " 'n_required_iterations_',\n",
       " 'n_resources_',\n",
       " 'n_splits_',\n",
       " 'param_grid',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'refit',\n",
       " 'refit_time_',\n",
       " 'resource',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Aluno Nitai Bezerra\n",
    "> [@nitaibezerra](https://twitter.com/nitaibezerra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
